{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries(Abhishek)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset(Abhishek)\n",
    "dataset = pd.read_csv(r'D:\\anaconda\\amazon-fine-food-reviews\\Reviews.csv')[:500]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding shape of dataset(Abhishek)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                Summary  \\\n",
       "0  B001E4KFG0  Good Quality Dog Food   \n",
       "1  B00813GRG4      Not as Advertised   \n",
       "2  B000LQOCH0  \"Delight\" says it all   \n",
       "3  B000UA0QIQ         Cough Medicine   \n",
       "4  B006K2ZZ7K            Great taffy   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping irrelevant features and taking relavent features from dataset(Abhishek)\n",
    "dataset = dataset[['ProductId','Summary','Text']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0001PB9FE</th>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0001PB9FY</th>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0002567IW</th>\n",
       "      <td>Five minutes in, one tentacle was bitten off, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00029XIZI</th>\n",
       "      <td>My Scotties were full of hot spots and when I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00061KYVI</th>\n",
       "      <td>i love this product cant find it locally. Some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text\n",
       "ProductId                                                    \n",
       "B0001PB9FE  I don't know if it's the cactus or the tequila...\n",
       "B0001PB9FY  I don't know if it's the cactus or the tequila...\n",
       "B0002567IW  Five minutes in, one tentacle was bitten off, ...\n",
       "B00029XIZI  My Scotties were full of hot spots and when I ...\n",
       "B00061KYVI  i love this product cant find it locally. Some..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_text = dataset.groupby('ProductId').agg({'Text':'; '.join})\n",
    "merged_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0001PB9FE</th>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0001PB9FY</th>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0002567IW</th>\n",
       "      <td>Sad outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00029XIZI</th>\n",
       "      <td>Miracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00061KYVI</th>\n",
       "      <td>french's roast'n bags; best roast ever; Franch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Summary\n",
       "ProductId                                                    \n",
       "B0001PB9FE                    The Best Hot Sauce in the World\n",
       "B0001PB9FY                    The Best Hot Sauce in the World\n",
       "B0002567IW                                        Sad outcome\n",
       "B00029XIZI                                            Miracle\n",
       "B00061KYVI  french's roast'n bags; best roast ever; Franch..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_summary = dataset.groupby('ProductId').agg({'Summary':'; '.join})\n",
    "merged_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a bunch of word which are frequently using in chat(Abhishek)\n",
    "short_words = {\n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the dataset.Text(Abhishek)\n",
    "x_cleaned = []\n",
    "for i, rows in merged_text.iterrows():\n",
    "    words = [e.lower() for e in rows.Text.split()]\n",
    "    word_clean = [word for word in words if 'http' not in word and word not in set(stopwords.words('english'))]\n",
    "    new_text = []\n",
    "    for word in word_clean:\n",
    "        if word in short_words:\n",
    "            new_text.append(short_words[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    word_cleaned = ' '.join(new_text)\n",
    "    x_cleaned.append(word_cleaned)\n",
    "corpus =[]\n",
    "for i in range(len(x_cleaned)):\n",
    "    review = re.sub(r'\\W',' ', str(x_cleaned[i]))\n",
    "    review = re.sub(r'\\s+[a-z]\\s+',' ', review)\n",
    "    review = re.sub(r'^br',' ', review)\n",
    "    review = re.sub(r'^amp',' ', review)\n",
    "    review = re.sub(r'\\s+',' ', review)\n",
    "    review = re.sub(r'^\\s+','', review)\n",
    "    corpus.append(review)\n",
    "Cleaned_text = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning dataset.Summary(Abhishek)\n",
    "y_cleaned = []\n",
    "for i, rows in merged_summary.iterrows():\n",
    "    words = [e.lower() for e in rows.Summary.split()]\n",
    "    word_clean = [word for word in words if 'http' not in word]\n",
    "    new_text = []\n",
    "    for word in word_clean:\n",
    "        if word in short_words:\n",
    "            new_text.append(short_words[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    word_cleaned = ' '.join(new_text)\n",
    "    y_cleaned.append(word_cleaned)\n",
    "corpus =[]\n",
    "for i in range(len(y_cleaned)):\n",
    "    review = re.sub(r'\\W',' ', str(y_cleaned[i]))\n",
    "    review = re.sub(r'\\s+[a-z]\\s+',' ', review)\n",
    "    review = re.sub(r'^br',' ', review)\n",
    "    review = re.sub(r'^amp',' ', review)\n",
    "    review = re.sub(r'\\s+',' ', review)\n",
    "    review = re.sub(r'^\\s+','', review)\n",
    "    corpus.append(review)\n",
    "Cleaned_summary = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned review  1\n",
      "the best hot sauce in the world\n",
      "know cactus tequila unique combination ingredients flavour hot sauce makes one kind picked bottle trip brought back home us totally blown away realized simply find anywhere city bummed br br now magic internet case sauce ecstatic it br br if love hot sauce mean really love hot sauce want sauce tastelessly burns throat grab bottle tequila picante gourmet de inclan realize taste it never want use sauce br br thank personal incredible service \n",
      "\n",
      "\n",
      "Cleaned review  2\n",
      "the best hot sauce in the world\n",
      "know cactus tequila unique combination ingredients flavour hot sauce makes one kind picked bottle trip brought back home us totally blown away realized simply find anywhere city bummed br br now magic internet case sauce ecstatic it br br if love hot sauce mean really love hot sauce want sauce tastelessly burns throat grab bottle tequila picante gourmet de inclan realize taste it never want use sauce br br thank personal incredible service \n",
      "\n",
      "\n",
      "Cleaned review  3\n",
      "sad outcome\n",
      "five minutes in one tentacle bitten off ball inside cracked half durable enough dog toy disappointed dog \n",
      "\n",
      "\n",
      "Cleaned review  4\n",
      "miracle\n",
      "scotties full hot spots used within week hot spots gone smell kinda strong bad tolerablel \n",
      "\n",
      "\n",
      "Cleaned review  5\n",
      "french roast bags best roast ever franch is the best\n",
      "love product cant find locally sometimes little way stores it but also love chicken pork chop bags every store go look lastplace found meat market best way cook roast local grocery went buisness could find product till looked here please continue keep product available always pleasure find french products web markets area made bargain carry nothing mccormacks bland tasteless seasonings br br this flavorful cooking bag mix ever find \n",
      "\n",
      "\n",
      "Cleaned review  6\n",
      "great beans good stuff excellent exactly what expected these are the best \n",
      "ordered coffee themed wedding arrived fight friends smelled tasted good literally hide box wedding big hit wedding day none left put tables great tasting product lowest price have seen these delicious chocolate excellent espresso bean perfect roast purpose crunchy bitter covered espresso beans 5 pounds product exactly advertised fresh unfortunately keep candy dish office going fast need reorder keep demand chocolate covered espresso beans wonderful chocolate dark rich bean inside delightful blend flavors enough caffine really give zing \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizing cleaned dataset(Abhishek)\n",
    "for i in range(6):\n",
    "    print('Cleaned review ', i+1)\n",
    "    print(Cleaned_summary[i])\n",
    "    print(Cleaned_text[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary that maps words to its number of occurances(Abhishek)\n",
    "word2count = {}\n",
    "for text in Cleaned_text:\n",
    "    for word in text.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for summary in Cleaned_summary:\n",
    "    for word in summary.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary that maps text.words to a unique integer(Abhishek)\n",
    "textword2int = {}\n",
    "threshold = 20\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        textword2int[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary that maps summary.words to a unique integer(Abhishek)\n",
    "summaryword2int = {}\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        summaryword2int[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding tokens to our dictionary(Abhishek)\n",
    "tokens = ['<PAD>','<EOS>','<OUT>','<SOS>']\n",
    "for token in tokens:\n",
    "    textword2int[token] = len(textword2int) + 1\n",
    "    summaryword2int[token] = len(summaryword2int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a inverse dictionary for summaryword2int(Abhishek)\n",
    "summaryint2word = {w_i:w for w,w_i in summaryword2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding End of String token to every summary(Abhishek)\n",
    "for i in range(len(Cleaned_summary)):\n",
    "    Cleaned_summary[i] += ' <EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translating all the text into integer and replacing <OUT> for those words which are filtered out(Abhishek)\n",
    "text2int = []\n",
    "for text in Cleaned_text:\n",
    "    ints = []\n",
    "    for word in text.split():\n",
    "        if word not in textword2int:\n",
    "            ints.append(textword2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(textword2int[word])\n",
    "    text2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translating all the summary into integer and replacing <OUT> for those words which are filtered out(Abhishek)\n",
    "summary2int = []\n",
    "for summary in Cleaned_summary:\n",
    "    ints = []\n",
    "    for word in summary.split():\n",
    "        if word not in summaryword2int:\n",
    "            ints.append(summaryword2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(summaryword2int[word])\n",
    "    summary2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
